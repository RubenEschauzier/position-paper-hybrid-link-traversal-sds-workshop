% chktex-file 8
\documentclass{ceurart}

%% One can fix some overfulls
\sloppy

\usepackage{minted}
\setminted{breaklines=true}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{url}
\usepackage{listings}

\begin{document}

\copyrightyear{2025}
\copyrightclause{Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).}

\conference{The Third International Workshop on Semantics in Dataspaces, co-located with the Extended Semantic Web Conference, June 01, 2025, Portorož, Slovenia}

\title{The Title of Your Contribution}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author[1]{Ruben Eschauzier}[%
orcid=0000-0002-6475-806X,
email=ruben.eschauzier@ugent.be
]
\author[1]{Ruben Taelman}[%
orcid=0000-0001-5118-256X,
email=ruben.taelman@ugent.be
]

\address[1]{Department of Electronics and Information Systems, Ghent University – imec}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Some cool abstract goes here!
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\begin{keywords}
  LaTeX class \sep
  paper template \sep
  paper formatting \sep
  CEUR-WS
\end{keywords}

\maketitle

%%
%% Reference a generic issue from the W3C Dataspaces Community Group, as described at https://dbis.rwth-aachen.de/SDS25/#submission. The author(s) must reference an existing issue in the GitHub repository, or add a new one.
\noindent This paper addresses (\href{https://github.com/w3c-cg/dataspaces/issues/2}{Issue \#2}) of the \href{https://www.w3.org/community/dataspaces/}{W3C Dataspaces Community Group}.
% TODO: This needs be be changed alot, is just an initial introduction written by Gemini
\section{Introduction} 
While centralizing data into warehouses or lakes can benefit query engine performance,
it is antithetical to the core principles of \emph{dataspaces}.
Dataspaces promote a decentralized ecosystem where data remains at the source, managed by independent participants under agreed-upon governance models.
This architectural shift introduces significant technical challenges for query engines,
which must now discover and query data across a vast network of sources,
each enforcing its own usage policies.

\emph{Centralized} querying requires collecting large volumes of proprietary or sensitive data in a single source, 
which conflicts with the requirements for fine-grained sovereignty and minimized data replication.
Conversely, traditional \emph{federated} approaches~\cite{schwarte2011fedx,schmidt2011fedbench,heling2022federated} support decentralization
but typically assume a static federation of a small number (10–100) of uniform,
expressive endpoints (e.g., SPARQL endpoints)~\cite{dang2023fedshop}.
Enforcing complex usage policies~\cite{esteves2021odrl} on such heavyweight interfaces significantly
impacts performance~\cite{padia2015attribute}, and these engines struggle to scale to the thousands of sources characteristic of a dataspace.

In contrast, realistic dataspace environments involve a massive number of permissioned sources 
exposing data through highly \emph{heterogeneous interfaces}~\cite{halevy2006principles,curry2019dataspaces}. 
Rather than a uniform layer of SPARQL endpoints, a dataspace participant may expose data via generic HTTP documents,
constrained APIs, derived views, or specialized query services.
Due to the scale and autonomy of the dataspace, the complete set of relevant sources 
and their specific interface capabilities is possibly unknown during query time. 
Such an environment requires a \emph{hybrid} federation approach capable of querying across diverse data interfaces
, discovered at runtime, without prior centralization.

\emph{Link Traversal-based Query Processing (LTQP)} is an approach that meets these needs by discovering data sources 
during execution via hypermedia links found in earlier results. 
Starting from seed references (e.g., a self-description or catalog entry), it follows links asynchronously.
While LTQP is traditionally defined as an approach for querying over federated \emph{hypermedia} documents by following links at runtime,
data within a dataspace is often exposed through diverse access interfaces that may not support standard hypermedia traversal and querying.

We propose \emph{Hybrid LTQP}, a generalization of link traversal that supports the diverse access methods found in dataspaces—including SPARQL endpoints,
materialized views, and Triple Pattern Fragments (TPF)~\cite{verborgh2016triple}. 
To leverage these varied levels of expressivity, a hybrid engine must offload computation to the server whenever possible. 
For instance, a SPARQL endpoint can execute complex sub-queries locally. 
By leveraging internal indexing and local data knowledge, the endpoint can produce results far more efficiently than a client-side LTQP engine.
Offloading these tasks to capable endpoints significantly reduces overall query latency.
However, building such a system introduces several unresolved challenges. 
In this paper, we review the state-of-the-art in hybrid querying, analyze related work, and outline open issues for future research.

\section{Related Work}

While Hybrid LTQP has previously been discussed in literature, 
the exact definition of hybrid link traversal querying varies between papers.

\subsection{Hybrid Traversal - Local vs Remote}

A branch of hybrid link traversal querying uses precomputed indexes, either located within the decentralized environment or computed locally to
speed-up query execution or source discovery. The first of such approaches, 
uses precomputed indexes to rerank sources based on relevance to the query's triple pattern and joins.
and retrieves them to execute queries over.~\cite{ladwig2010linked}. Other works~\cite{sabri2015hybrid} propose to cache information on sources to
help in prioritization of sources.

Another approach is to store entire RDF graphs in local stores to quickly execute parts of the query.
For this approach, non-blocking indexed-based operators~\cite{ladwig2011sihjoin} are used to leverage the locally computed indexes for faster
query execution.
A major limitation is the freshness of the data in the store, which can quickly go stale for high velocity data sources.
Various methods, like freshness (or coherence)-aware query processing exist~\cite{umbrich2012hybrid}, however it remains a limitation.

\subsection{Hybrid Traversal - Closed Systems}

Other approaches integrate into the dataspace itself. ESPRESSO~\cite{ragab2023espresso} is such an approach, 
it is a framework around the Solid dataspace specifically that defines several apps in the dataspace to perform certain \(optimization\) tasks.
In the Solid environment, data is stored into personal data vaults. These vaults use the Linked Data Platform~\cite{ldp} to arrange the data into a folder-like
structure.
To avoid traversing the entire pod to query it, ESPRESSO uses the \textit{Brewmaster} application to locally create indexes of the pod 
and uses the \textit{CoffeeFilter} application to search its contents.
In addition, ESPRESSO uses an overlay network to distribute end-user queries to relevant data resources across Solid servers, 
where each Solid server is mapped to a federated database node in the overlay network.

Unlike approaches based on link traversal or service discovery within Solid, 
ESPRESSO relies on an explicitly configured overlay network, 
with no mechanism for dynamically discovering participating servers or query endpoints.
Futhermore, currently ESPRESSO only supports distributed keyword-based search, it does not support SPARQL queries over the sources.

While these approaches do hybrid link traversal, they significantly deviate from our interpretation of hybrid traversal.
This in contrast to the setting described in this paper where the discovered sources themselves are heterogeneous, serendiptiously discovered, 
and cannot be assumed to be present for every source within the dataspace. 

\subsection{Hybrid Link Traversal over Heterogeneous Sources}
State-of-the-art LTQP engines, most notably Comunica~\cite{taelman2018comunica, taelman2023link}, demonstrate hybrid capabilities by dynamically federating 
over discovered SPARQL endpoints, TPF interfaces, and hypermedia documents.
However, these systems are currently limited by a \emph{lowest common denominator} strategy: they fail
to leverage the full expressivity of sophisticated interfaces.
For instance, upon discovering a SPARQL endpoint, existing engines restrict interaction to simple \emph{triple pattern} lookups.

This forces the client to retrieve high volumes of intermediate results and perform joins locally,
effectively negating the optimization and latency benefits of server-side execution.

\section{Challenges with Hybrid Link Traversal}
In this section, we will outline specific identified problems with hybrid link traversal making implementation difficult.

\subsection{Establishing Exclusive Groups}

In classical federated query processing, \emph{exclusive groups} are sets of triple patterns within a query
that can \emph{only} be answered by a single source~\cite{schwarte2011fedx}. 
instead of retrieving results for individual triple patterns and joining them locally,
the engine can delegate the entire group as a single sub-query (e.g., a Basic Graph Pattern) to the remote endpoint. 
This technique significantly reduces the number of remote requests and processed intermediate results~\cite{aimonier2024fedup,schwarte2011fedx}.

The identification of exclusive groups is a strict requirement for this sub-query delegation. 
If a query engine cannot verify that a group of patterns belongs \emph{exclusively} to a single source,
it cannot safely dispatch them as a conjunctive sub-query (BGP).
Doing so risks \emph{incomplete results} because the endpoint will execute a server-side join.
If the endpoint lacks data for one of the patterns, or if valid join partners reside on a different server,
the server-side join execution will filter out bindings that could have been successfully joined with data from another source.
Thus, the exclusive grouping strategy fails to produce the valid distributed join results.

Federation engines like \emph{FedX}~\cite{schwarte2011fedx}, \emph{HiBISCuS}~\cite{saleem2014hibiscus}, and \emph{FedUp}~\cite{aimonier2024fedup}
rely on either prior knowledge on the content of the federation members, or issue queries (such as ASK) to determine these groups.

For Hybrid Link Traversal to use SPARQL endpoints to compute joins locally, the engine should also identify exclusive groups.
The problem is the unbounded nature of LTQP~\cite{hartig2012foundations}. As during LTQP the query engine does not have access to
all sources it will query over, exclusive groups can never be established.
Even if we move to a finite web~\cite{hartig2012foundations}, the engine would have to first traverse all reachable~\cite{hartig2012foundations}
sources before exclusive groups can be determined.
This is antithetical to the streaming nature of LTQP engines~\cite{taelman2018comunica, hartig2013squin} and will delay time to first result unacceptably.
Thus, traditional approaches for determining exclusive groups are not applicable.

\subsubsection{Research Avenues}

\textbf{Discoverable Indexes:} 
Indexes can be effectively used to catalogue the data sources present in a dataspace.
These indexes could be deployed as services, similar to approaches like ESPRESSO~\cite{ragab2023espresso}, pointing towards available source URIs
and potentially exposing summary statistics.
Using such indexes to quickly determine relevant sources, LTQP engines can apply traditional federation techniques 
to establish exclusive groups and perform source selection.

\textbf{Caching:}
Similar to discoverable indexes, caches provide prior knowledge about the data sources present in a dataspace.
Provided the cache maintains a degree of freshness and completeness, the query engine can perform a `simulated traversal' 
offline over the cached data to identify relevant sources.
Any gaps in this knowledge can then be supplemented by live traversal prior to or during execution.

\textbf{Authoritativeness Assumptions:}
Establishing exclusive groups in a decentralized dataspace requires a notion of \emph{source authority}~\cite{bogaerts2024distributed}.
Under standard Link Traversal, any reachable source can assert triples about any subject
(e.g., a third-party source asserting \texttt{<P1> foaf:knows <P2>}), creating a ``wild west'' of data where 
no single source can be deemed the exclusive authority for a topic.
This lack of authority prevents the query engine from determining if a set of patterns can be safely delegated to a single endpoint.

A possible solution is restricting the scope of validity such that a data source is the \emph{sole authority} 
for triples where the subject corresponds to the source's own URI (or a URI within its controlled namespace).
By enforcing this \emph{Subject Authority Constraint}, the query engine can 
statically determine that all triples matching \texttt{<SourceA> ?p ?o} reside exclusively at \emph{Source A}.
This allows the engine to safely treat such patterns as an exclusive group, 
enabling the delegation of complex sub-queries (e.g., BGPs) to hybrid sources like SPARQL endpoints without the risk of incomplete results.

\subsection{Integrating Dynamically Delegated Sub-queries into the Query Plan}
When exclusive groups are identified and subqueries are dynamically pushed to expressive server-side interfaces,
the resulting intermediate results must fit into the existing query plan.

In the traditional optimize-then-execute approach,
used by Comunica-link-traversal~\cite{taelman2018comunica,taelman2023link} and SQUIN~\cite{hartig2013squin} (except in~\cite{hartig2016walking}),
the query plan is constructed before execution and evaluated over dynamically discovered sources.

Thus, an exclusive group can only be integrated if the precomputed plan already produces an intermediate result that exactly matches 
the triple patterns in that group.

As an example, consider a query plan with the join structure
\[
(T_{1} \Join T_{2}) \Join (T_{3} \Join T_{4}).
\]
If the engine discovers an exclusive group consisting of the triple patterns
\(\{T_{2}, T_{3}\}\), this group cannot be integrated into the plan.
The plan never produces an intermediate result of the form
\(T_{2} \Join T_{3}\), since these patterns occur in different subtrees.
As a result, the exclusive group does not fit into the existing join structure
and cannot be pushed as a single subquery.

\subsubsection{Research Avenues}
A clear path forward is the use of adaptive query processing techniques.
These techniques should enable low-cost plan switching without discarding intermediate results,
as the large number of sources in a dataspace would otherwise lead to plan thrashing.
Algorithms such as Eddies~\cite{avnur2000eddies}, SteMs~\cite{raman2003using} (as used in~\cite{hartig2016walking}),
and STAIRs~\cite{deshpande2004lifting} are viable candidates due to their tuple-level adaptivity.
However, the literature provides no analysis of their performance characteristics in the context of LTQP,
nor guidance on the design of adaptive routing strategies that determine how tuples are forwarded.

\subsection{Discovery of Data in SPARQL endpoints}

\subsection{Alternative View Deduplication}


% Please adjust accordingly. See https://ceur-ws.org/GenAI/Policy.html
%% The declaration on generative AI comes in effect
%% in Janary 2025. See also
%% https://ceur-ws.org/GenAI/Policy.html
\section*{Declaration on Generative AI}
  %The author(s) have not employed any Generative AI tools.
 
  % Use the activity taxonomy in ceur-ws.org/genai-tax.html
  During the writing of this paper, the author(s) used DeepL and GPT-4o in order to: Grammar, translation and spelling check. After using these tool(s)/service(s), the author(s) reviewed and edited the content as needed and take(s) full responsibility for the publication’s content.

%%
%% Define the bibliography file to be used
\bibliography{bilbiography}

\end{document}
